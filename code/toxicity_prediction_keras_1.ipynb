{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Copy of toxicity_prediction_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "epiTpMk96vR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPu4Nt9q6vR3",
        "colab_type": "code",
        "outputId": "b6947425-a4db-4598-e58b-084f9e96702b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n",
        "from tensorflow.keras.layers import Input, Flatten, Activation, RepeatVector\n",
        "from tensorflow.keras.layers import Permute, multiply, Lambda, Dropout\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from keras import backend as K\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Rg7ctX6vR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to plot results\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    \n",
        "# Precision = TP / (TP+FP).\n",
        "def precision(decoded_vals, target_vals):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    for i in range(len(decoded_vals)):\n",
        "        TP += int(decoded_vals[i] == 0 and target_vals[i] == 0)\n",
        "        FP += int(decoded_vals[i] == 0 and target_vals[i] == 1)\n",
        "\n",
        "    return 1.0 * TP / (TP + FP)\n",
        "\n",
        "# Recall = TP / (TP+FN).\n",
        "def recall(decoded_vals, target_vals):\n",
        "    TP = 0\n",
        "    FN = 0\n",
        "    for i in range(len(decoded_vals)):\n",
        "        TP += int(decoded_vals[i] == 0 and target_vals[i] == 0)\n",
        "        FN += int(decoded_vals[i] == 1 and target_vals[i] == 0)\n",
        "\n",
        "    return 1.0 * TP / (TP + FN)\n",
        "\n",
        "def balanced_accuracy(decoded_vals, target_vals):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    for i in range(len(decoded_vals)):\n",
        "      TP += int(decoded_vals[i] == 0 and target_vals[i] == 0)\n",
        "      FP += int(decoded_vals[i] == 0 and target_vals[i] == 1)\n",
        "      TN += int(decoded_vals[i] == 1 and target_vals[i] == 1)\n",
        "      FN += int(decoded_vals[i] == 1 and target_vals[i] == 0)\n",
        "\n",
        "    return 0.5 * TP / (TP + FN) + 0.5 * TN / (TN + FP)\n",
        "\n",
        "def evaluate_precision_recall(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    rounded = [round(x[0]) for x in predictions]\n",
        "    # predictions = model.predict_classes(X_test)\n",
        "    print(\"Precision: \" + str(precision(rounded, y_test)))\n",
        "    print(\"Recall: \" + str(recall(rounded, y_test)))\n",
        "    print(\"Balanced Accuracy: \" + str(balanced_accuracy(rounded, y_test)))\n",
        "    return predictions, rounded\n",
        "\n",
        "def evaluate_balanced_accuracy(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    rounded = [round(x[0]) for x in predictions]\n",
        "    return balanced_accuracy(rounded, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yL_OtAIA6vR8",
        "colab_type": "code",
        "outputId": "64782df5-ce65-409b-8cfa-2bb86750ce48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Load data.\n",
        "drugbank_smile_data_train_url = \"https://raw.githubusercontent.com/vli1721/cs281-project/master/drugbank_smile_data_filtered_train.csv?token=AHRDF6OBWOFKKK4AKOCY2N257WWVE\"\n",
        "drugbank_smile_data_test_url = \"https://raw.githubusercontent.com/vli1721/cs281-project/master/drugbank_smile_data_filtered_test.csv?token=AHRDF6NISTEXL5L2SDWX4XS57WWOY\"\n",
        "drugbank_smile_data_unlabeled_url = \"https://raw.githubusercontent.com/vli1721/cs281-project/master/drugbank_smile_data_unlabeled.csv?token=AHRDF6J7N3K6FJZTVVSB7DC57WWRQ\"\n",
        "\n",
        "smile_data_train = pd.read_csv(drugbank_smile_data_train_url)\n",
        "smile_data_test = pd.read_csv(drugbank_smile_data_test_url)\n",
        "smile_data_unlabeled = pd.read_csv(drugbank_smile_data_unlabeled_url)\n",
        "\n",
        "max_len_train = max(list(map(len, smile_data_train[\"smile\"])))\n",
        "max_len_test = max(list(map(len, smile_data_test[\"smile\"])))\n",
        "max_len_unlabeled = max(list(map(len, smile_data_unlabeled[\"smile\"])))\n",
        "max_len = max(max_len_train, max_len_test, max_len_unlabeled)\n",
        "\n",
        "print(\"Max Length Train: \" + str(max_len_train))\n",
        "print(\"Max Length Test: \" + str(max_len_test))\n",
        "print(\"Max Length Unlabeled: \" + str(max_len_unlabeled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Length Train: 1526\n",
            "Max Length Test: 351\n",
            "Max Length Unlabeled: 1695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJKdCkUX6vSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants\n",
        "NUM_CHARS = 128\n",
        "# SOS_token = 129\n",
        "# EOS_token = 130\n",
        "INPUT_SIZE = max_len # + 2\n",
        "MAX_LENGTH = max_len\n",
        "HIDDEN_SIZE = 50\n",
        "EMBEDDING_SIZE = 64\n",
        "OUTPUT_SIZE = NUM_CHARS + 2\n",
        "NUM_LAYERS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVrMTMOK6vSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X-values are SMILE strings, encoded as tensors of ASCII values.\n",
        "# Y-values are toxicity ratings (1 indicates toxic, 0 indicates non-toxic).\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for index, row in smile_data_train.iterrows():\n",
        "    X_train.append(list(map(ord, row[\"smile\"])))\n",
        "    y_train.append(row[\"toxicity\"])\n",
        "for index, row in smile_data_test.iterrows():\n",
        "    X_test.append(list(map(ord, row[\"smile\"])))\n",
        "    y_test.append(row[\"toxicity\"])\n",
        "\n",
        "X_train = sequence.pad_sequences(np.array(X_train), maxlen=MAX_LENGTH)\n",
        "y_train = np.array(y_train)\n",
        "X_test = sequence.pad_sequences(np.array(X_test), maxlen=MAX_LENGTH)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2sFU5ilIAhL",
        "colab_type": "code",
        "outputId": "82bb77b4-4e7b-4301-b3fa-d0a318cf161f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Proportion of non-toxic drugs in train set: \" + str((len(y_train) - sum(y_train))/len(y_train)))\n",
        "print(\"Proportion of non-toxic drugs in test set: \" + str((len(y_test) - sum(y_test))/len(y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion of non-toxic drugs in train set: 0.9163498098859315\n",
            "Proportion of non-toxic drugs in test set: 0.920303605313093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUZUn1WW6vSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate train main-validation split (80-20).\n",
        "X_train_main, X_train_val, y_train_main, y_train_val = train_test_split(np.array(X_train), np.array(y_train), train_size=0.8, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC0U46CLuY-m",
        "colab_type": "code",
        "outputId": "6032576a-5f57-47e9-f724-2ed00071f3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Stratified Sampling: Set class weights for imbalanced classes (https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras).\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "class_weights_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5456431535269709, 1: 5.9772727272727275}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSe5pVIpaWr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "balanced_accuracy_results_lstm_no_attention = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3p2vPk-6vSM",
        "colab_type": "code",
        "outputId": "16c49126-9c3e-4b16-ac39-bf38396f0156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "# LSTM without attention. (https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/)\n",
        "lstm_no_attention = Sequential()\n",
        "lstm_no_attention.add(Embedding(NUM_CHARS, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
        "lstm_no_attention.add(LSTM(HIDDEN_SIZE, return_sequences = True))\n",
        "lstm_no_attention.add(Dropout(0.5))\n",
        "lstm_no_attention.add(LSTM(HIDDEN_SIZE, return_sequences = True))\n",
        "lstm_no_attention.add(Dropout(0.5))\n",
        "lstm_no_attention.add(LSTM(HIDDEN_SIZE))\n",
        "lstm_no_attention.add(Dropout(0.5))\n",
        "lstm_no_attention.add(Dense(1, activation='sigmoid'))\n",
        "lstm_no_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(lstm_no_attention.summary())\n",
        "\n",
        "print_weights_lstm_no_attention = LambdaCallback(on_epoch_end=lambda epoch, logs: print(lstm_no_attention.layers[2].get_weights()))\n",
        "# store_balancedAccuracy_lstm_no_attention = LambdaCallback(on_epoch_end=lambda epoch, logs: balanced_accuracy_results_lstm_no_attention.append(evaluate_balanced_accuracy(lstm_no_attention, )))\n",
        "\n",
        "lstm_history = lstm_no_attention.fit(X_train, y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      epochs=15, batch_size=64, class_weight=class_weights_dict)\n",
        "                      \n",
        "# lstm_no_attention.fit(X_train_main, y_train_main,\n",
        "#                       validation_data=(X_train_val, y_train_val),\n",
        "#                       epochs=5, batch_size=32, class_weight=class_weights_dict,\n",
        "#                       callbacks=[print_weights_lstm_no_attention])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1695, 64)          8192      \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 1695, 50)          23000     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1695, 50)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 1695, 50)          20200     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1695, 50)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 71,643\n",
            "Trainable params: 71,643\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 2104 samples, validate on 527 samples\n",
            "Epoch 1/15\n",
            "2104/2104 [==============================] - 298s 142ms/sample - loss: 0.6852 - acc: 0.7115 - val_loss: 0.7005 - val_acc: 0.4307\n",
            "Epoch 2/15\n",
            "2104/2104 [==============================] - 291s 138ms/sample - loss: 0.6547 - acc: 0.5109 - val_loss: 0.7354 - val_acc: 0.4175\n",
            "Epoch 3/15\n",
            "2104/2104 [==============================] - 290s 138ms/sample - loss: 0.6355 - acc: 0.5594 - val_loss: 0.7132 - val_acc: 0.4801\n",
            "Epoch 4/15\n",
            "2104/2104 [==============================] - 289s 138ms/sample - loss: 0.6303 - acc: 0.4753 - val_loss: 0.5332 - val_acc: 0.6736\n",
            "Epoch 5/15\n",
            "2104/2104 [==============================] - 292s 139ms/sample - loss: 0.6236 - acc: 0.5352 - val_loss: 0.6259 - val_acc: 0.5389\n",
            "Epoch 6/15\n",
            "2104/2104 [==============================] - 291s 138ms/sample - loss: 0.6044 - acc: 0.5656 - val_loss: 0.4800 - val_acc: 0.7097\n",
            "Epoch 7/15\n",
            "2104/2104 [==============================] - 290s 138ms/sample - loss: 0.5896 - acc: 0.5936 - val_loss: 0.5236 - val_acc: 0.6736\n",
            "Epoch 8/15\n",
            "2104/2104 [==============================] - 290s 138ms/sample - loss: 0.5779 - acc: 0.5970 - val_loss: 0.5307 - val_acc: 0.6641\n",
            "Epoch 9/15\n",
            "2104/2104 [==============================] - 292s 139ms/sample - loss: 0.5881 - acc: 0.5803 - val_loss: 0.5582 - val_acc: 0.6091\n",
            "Epoch 10/15\n",
            "2104/2104 [==============================] - 291s 138ms/sample - loss: 0.5643 - acc: 0.5993 - val_loss: 0.6218 - val_acc: 0.5863\n",
            "Epoch 11/15\n",
            "2104/2104 [==============================] - 290s 138ms/sample - loss: 0.5698 - acc: 0.6302 - val_loss: 0.5814 - val_acc: 0.6129\n",
            "Epoch 12/15\n",
            "1728/2104 [=======================>......] - ETA: 49s - loss: 0.5667 - acc: 0.5949"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLZD2Gte-rWF",
        "colab_type": "code",
        "outputId": "effc27ae-29de-4ac1-9133-c0f157979647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "predictions_lstm_no_attention, rounded_lstm_no_attention = evaluate_precision_recall(lstm_no_attention, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9785407725321889\n",
            "Recall: 0.47010309278350515\n",
            "Balanced Accuracy: 0.6755277368679431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0NyXdfk7orF",
        "colab_type": "code",
        "outputId": "bc2481fe-52ae-4004-ce0b-8a713a0fc30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "plt.plot(lstm_no_attention.history.history['acc'])\n",
        "plt.plot(lstm_no_attention.history.history['val_acc'])\n",
        "plt.plot(lstm_no_attention.history.history['loss'])\n",
        "plt.plot(lstm_no_attention.history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e794e0a2d254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_no_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_no_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_no_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_no_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lstm_no_attention' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHX4mS4uwkV-",
        "colab_type": "code",
        "outputId": "41f521ea-226f-4feb-ea9b-63bbf6dd8591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(lstm_no_attention.history.history['acc'])\n",
        "plt.plot(lstm_no_attention.history.history['val_acc'])\n",
        "plt.plot(lstm_no_attention.history.history['loss'])\n",
        "plt.plot(lstm_no_attention.history.history['val_loss'])\n",
        "plt.title('Results')\n",
        "plt.legend(['train_acc', 'test_acc', 'train_loss', 'test_loss'], loc = 'best')\n",
        "plt.xlabel('epoch')\n",
        "# plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmDhhAd0YY+KEBXRjjIkTFtCNMSZO/D98LdEIGoqPvgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSb3T-rrGkMG",
        "colab_type": "code",
        "outputId": "8c53951c-8c0a-41a7-9802-9e6e7b8de448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# evaluate the keras model\n",
        "_, accuracy = lstm_no_attention.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "527/527 [==============================] - 12s 23ms/sample - loss: 0.6022 - acc: 0.6148\n",
            "Accuracy: 61.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp5arRkb-srl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(NUM_CHARS, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
        "  model.add(LSTM(HIDDEN_SIZE))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64s3uLSdAgLR",
        "colab_type": "code",
        "outputId": "01b4218e-b712-4dfa-c5b2-a1d54c164b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=1, batch_size=64, verbose=1)\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "results = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1402 samples\n",
            "1402/1402 [==============================] - 50s 36ms/sample - loss: 0.4407 - acc: 0.8802\n",
            "702/702 [==============================] - 5s 7ms/sample - loss: 0.2978 - acc: 0.9145\n",
            "Train on 1403 samples\n",
            "1403/1403 [==============================] - 49s 35ms/sample - loss: 0.4426 - acc: 0.9016\n",
            "701/701 [==============================] - 5s 7ms/sample - loss: 0.2978 - acc: 0.9144\n",
            "Train on 1403 samples\n",
            "1403/1403 [==============================] - 49s 35ms/sample - loss: 0.4603 - acc: 0.8810\n",
            "701/701 [==============================] - 5s 7ms/sample - loss: 0.2973 - acc: 0.9144\n",
            "Baseline: 91.44% (0.01%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQlqDcAAz4O",
        "colab_type": "code",
        "outputId": "023b8d69-fbcd-41ee-a0d8-9b1ccc16d457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "estimator.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-687bf9adead9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m    240\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql82tvFIcqAE",
        "colab_type": "code",
        "outputId": "e2a6ae9b-d57a-499d-80a7-aaff03cf4c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        }
      },
      "source": [
        "# Bidirectional LSTM without Attention (https://keras.io/examples/imdb_bidirectional_lstm/)\n",
        "bi_lstm_no_attention = Sequential()\n",
        "bi_lstm_no_attention.add(Embedding(NUM_CHARS, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
        "bi_lstm_no_attention.add(Bidirectional(LSTM(HIDDEN_SIZE)))\n",
        "# bi_lstm_no_attention.add(Dropout(0.5))\n",
        "bi_lstm_no_attention.add(Dense(1, activation='sigmoid'))\n",
        "bi_lstm_no_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(bi_lstm_no_attention.summary())\n",
        "\n",
        "bi_lstm_no_attention.fit(X_train_main, y_train_main,\n",
        "                         validation_data=(X_train_val, y_train_val),\n",
        "                         epochs=10, batch_size=64, class_weight=class_weights_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 1695, 64)          8192      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               132000    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 140,393\n",
            "Trainable params: 140,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1683 samples, validate on 421 samples\n",
            "Epoch 1/10\n",
            "1683/1683 [==============================] - 184s 109ms/sample - loss: 0.6919 - acc: 0.7094 - val_loss: 0.6897 - val_acc: 0.4656\n",
            "Epoch 2/10\n",
            "1683/1683 [==============================] - 178s 106ms/sample - loss: 0.6682 - acc: 0.3702 - val_loss: 0.6862 - val_acc: 0.5226\n",
            "Epoch 3/10\n",
            "  64/1683 [>.............................] - ETA: 2:33 - loss: 0.4519 - acc: 0.5781"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-7a83b5dbc708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m bi_lstm_no_attention.fit(X_train_main, y_train_main,\n\u001b[1;32m     10\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                          epochs=10, batch_size=64, class_weight=class_weights_dict)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw5c9qR7fLxy",
        "colab_type": "code",
        "outputId": "0aaae820-1bd7-4329-ba2e-ca14249ee93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predictions_bi_lstm_no_attention = evaluate_precision_recall(bi_lstm_no_attention, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9688888888888889\n",
            "Recall: 0.44948453608247424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8fs2hEpB0ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants\n",
        "NUM_CHARS = 128\n",
        "# SOS_token = 129\n",
        "# EOS_token = 130\n",
        "INPUT_SIZE = max_len# + 2\n",
        "MAX_LENGTH = max_len\n",
        "HIDDEN_SIZE = 150\n",
        "EMBEDDING_SIZE = 64\n",
        "OUTPUT_SIZE = NUM_CHARS + 2\n",
        "NUM_LAYERS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_1zqjKTDxgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create LSTM with Attention using Keras Functional API\n",
        "# (https://stackoverflow.com/questions/42918446/how-to-add-an-attention-mechanism-in-keras)\n",
        "def create_lstm_with_attention():\n",
        "    _input = Input(shape=[MAX_LENGTH])\n",
        "    embedded = Embedding(\n",
        "            input_dim=NUM_CHARS,\n",
        "            output_dim=EMBEDDING_SIZE,\n",
        "            input_length=MAX_LENGTH,\n",
        "            trainable=False,\n",
        "            mask_zero=False\n",
        "        )(_input)\n",
        "    activations = LSTM(HIDDEN_SIZE, return_sequences=True)(embedded)\n",
        "    # activations = Dropout(0.5)(activations)\n",
        "    \n",
        "    # Attention\n",
        "    attention = Dense(1, activation='tanh')(activations) # 'softmax'\n",
        "    # attention = Dense(1)(attention)\n",
        "    attention = Flatten()(attention)\n",
        "    attention = Activation('softmax')(attention)\n",
        "    attention = RepeatVector(HIDDEN_SIZE)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "    output_attention = multiply([activations, attention])\n",
        "\n",
        "    # output_attention = LSTM(HIDDEN_SIZE)(output_attention)\n",
        "\n",
        "    output_attention = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(HIDDEN_SIZE,))(output_attention)\n",
        "    output = Dense(1, activation='softmax')(output_attention)\n",
        "    lstm_attention = Model(inputs=[_input], outputs=output, name=\"lstm_attention\")\n",
        "    return lstm_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPwsefSb0atf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_weights = LambdaCallback(on_epoch_end=lambda epoch, logs: print(lstm_attention.layers[4].get_weights()))\n",
        "print_weights_2 = LambdaCallback(on_epoch_end=lambda epoch, logs: print(lstm_attention.layers[10].get_weights()))\n",
        "\n",
        "print_output = LambdaCallback(on_epoch_end=lambda epoch, logs: print(lstm_attention.layers[6].output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V3PDpKa-Qrz",
        "colab_type": "code",
        "outputId": "cef40405-1e5e-4037-8983-d72ebdf6a79a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lstm_attention = create_lstm_with_attention()\n",
        "# lstm_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "lstm_attention.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "print(lstm_attention.summary())\n",
        "\n",
        "lstm_attention.fit(X_train_main, y_train_main,\n",
        "                         validation_data=(X_train_val, y_train_val),\n",
        "                         epochs=3, batch_size=64, class_weight=class_weights_dict,\n",
        "                   callbacks = [print_weights, print_weights_2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm_attention\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 1695)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1695, 64)     8192        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 1695, 100)    66000       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1695, 1)      101         lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1695)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1695)         0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 100, 1695)    0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 1695, 100)    0           repeat_vector_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 1695, 100)    0           lstm_3[0][0]                     \n",
            "                                                                 permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 100)          0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            101         lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 74,394\n",
            "Trainable params: 66,202\n",
            "Non-trainable params: 8,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 1683 samples, validate on 421 samples\n",
            "Epoch 1/3\n",
            "1664/1683 [============================>.] - ETA: 0s - loss: 7.6777 - acc: 0.0823[]\n",
            "[array([[-0.14490704],\n",
            "       [-0.1818516 ],\n",
            "       [ 0.04249126],\n",
            "       [-0.21226996],\n",
            "       [-0.18462044],\n",
            "       [ 0.00492905],\n",
            "       [ 0.05130145],\n",
            "       [ 0.15602297],\n",
            "       [-0.1166463 ],\n",
            "       [ 0.13743073],\n",
            "       [-0.06296802],\n",
            "       [-0.19432431],\n",
            "       [-0.01407479],\n",
            "       [ 0.14479366],\n",
            "       [ 0.00510414],\n",
            "       [-0.00089699],\n",
            "       [ 0.06195498],\n",
            "       [ 0.07016042],\n",
            "       [-0.17647335],\n",
            "       [-0.05915695],\n",
            "       [-0.08574928],\n",
            "       [-0.17379485],\n",
            "       [ 0.05162159],\n",
            "       [ 0.23012367],\n",
            "       [ 0.09875152],\n",
            "       [-0.06605712],\n",
            "       [-0.14431444],\n",
            "       [-0.03216577],\n",
            "       [-0.21154591],\n",
            "       [-0.09521863],\n",
            "       [-0.17017195],\n",
            "       [ 0.14239842],\n",
            "       [-0.04361111],\n",
            "       [ 0.00381549],\n",
            "       [-0.06372131],\n",
            "       [ 0.0081847 ],\n",
            "       [-0.21632904],\n",
            "       [-0.08154707],\n",
            "       [ 0.10886809],\n",
            "       [-0.14797232],\n",
            "       [ 0.08600119],\n",
            "       [ 0.17134538],\n",
            "       [-0.09837258],\n",
            "       [ 0.01204851],\n",
            "       [ 0.23332098],\n",
            "       [-0.13377254],\n",
            "       [ 0.12842765],\n",
            "       [ 0.16594627],\n",
            "       [ 0.15987355],\n",
            "       [ 0.1435808 ],\n",
            "       [ 0.13204443],\n",
            "       [ 0.20825529],\n",
            "       [ 0.07454953],\n",
            "       [ 0.03717071],\n",
            "       [ 0.07807043],\n",
            "       [ 0.05503169],\n",
            "       [-0.12551022],\n",
            "       [ 0.2238726 ],\n",
            "       [ 0.24230748],\n",
            "       [ 0.13194805],\n",
            "       [-0.15785274],\n",
            "       [-0.2375337 ],\n",
            "       [-0.04093052],\n",
            "       [ 0.15048635],\n",
            "       [ 0.2140854 ],\n",
            "       [-0.08013655],\n",
            "       [ 0.05828658],\n",
            "       [-0.02145158],\n",
            "       [ 0.18904155],\n",
            "       [-0.15307269],\n",
            "       [ 0.15743715],\n",
            "       [-0.06922211],\n",
            "       [-0.21246196],\n",
            "       [ 0.13885331],\n",
            "       [ 0.16321239],\n",
            "       [-0.22508764],\n",
            "       [ 0.13808179],\n",
            "       [-0.24118637],\n",
            "       [ 0.20749938],\n",
            "       [ 0.2272425 ],\n",
            "       [ 0.02334183],\n",
            "       [-0.00094023],\n",
            "       [ 0.01365912],\n",
            "       [ 0.12843758],\n",
            "       [-0.02491862],\n",
            "       [ 0.13935941],\n",
            "       [-0.12988797],\n",
            "       [-0.16881031],\n",
            "       [-0.02199659],\n",
            "       [ 0.07290593],\n",
            "       [-0.17831671],\n",
            "       [ 0.22210664],\n",
            "       [-0.08770046],\n",
            "       [-0.15821849],\n",
            "       [-0.16736236],\n",
            "       [-0.10883527],\n",
            "       [ 0.06879029],\n",
            "       [-0.12275147],\n",
            "       [ 0.19288313],\n",
            "       [-0.109092  ]], dtype=float32), array([0.], dtype=float32)]\n",
            "1683/1683 [==============================] - 86s 51ms/sample - loss: 7.6805 - acc: 0.0820 - val_loss: 13.8728 - val_acc: 0.0903\n",
            "Epoch 2/3\n",
            " 384/1683 [=====>........................] - ETA: 59s - loss: 7.6693 - acc: 0.0833 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-16432562c096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                    callbacks = [print_weights, print_weights_2])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RberrL7ox-L",
        "colab_type": "code",
        "outputId": "85cfb0d5-0113-4b11-d726-facfb9ae2451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "predictions_lstm_attention, rounded_lstm_attention = evaluate_precision_recall(lstm_attention, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7deaa93a1be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_lstm_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded_lstm_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_precision_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-bbf39f5be2db>\u001b[0m in \u001b[0;36mevaluate_precision_recall\u001b[0;34m(model, X_test, y_test)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mrounded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# predictions = model.predict_classes(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-bbf39f5be2db>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(decoded_vals, target_vals)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mFP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Recall = TP / (TP+FN).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQWMEw2zzo7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_lstm_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UJeldgJCn8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rounded_lstm_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVknY95v_sFy",
        "colab_type": "code",
        "outputId": "a6ed3672-3509-4949-d09d-01f8be172ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(predictions_lstm_attention)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2FaNuJKf_sG",
        "colab_type": "code",
        "outputId": "aee53504-c172-4f72-dbb2-4eac3f11cece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions_lstm_attention"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4961562 ],\n",
              "       [0.49609172],\n",
              "       [0.49615976],\n",
              "       [0.49607486],\n",
              "       [0.4961688 ],\n",
              "       [0.49612573],\n",
              "       [0.49614757],\n",
              "       [0.4961554 ],\n",
              "       [0.4961159 ],\n",
              "       [0.49597448],\n",
              "       [0.49617523],\n",
              "       [0.49607423],\n",
              "       [0.49605054],\n",
              "       [0.4961135 ],\n",
              "       [0.49616486],\n",
              "       [0.49596468],\n",
              "       [0.4961772 ],\n",
              "       [0.49618816],\n",
              "       [0.49549094],\n",
              "       [0.49612513],\n",
              "       [0.4961008 ],\n",
              "       [0.4961989 ],\n",
              "       [0.49613893],\n",
              "       [0.49606025],\n",
              "       [0.49615124],\n",
              "       [0.49605876],\n",
              "       [0.4960235 ],\n",
              "       [0.496061  ],\n",
              "       [0.49608633],\n",
              "       [0.49609944],\n",
              "       [0.49620906],\n",
              "       [0.49543896],\n",
              "       [0.49595445],\n",
              "       [0.4960561 ],\n",
              "       [0.49603152],\n",
              "       [0.49607995],\n",
              "       [0.49614912],\n",
              "       [0.49606827],\n",
              "       [0.49612287],\n",
              "       [0.4961007 ],\n",
              "       [0.49611697],\n",
              "       [0.4960754 ],\n",
              "       [0.49570054],\n",
              "       [0.49610198],\n",
              "       [0.49594525],\n",
              "       [0.49615216],\n",
              "       [0.49611413],\n",
              "       [0.4961698 ],\n",
              "       [0.49586254],\n",
              "       [0.49608734],\n",
              "       [0.49582225],\n",
              "       [0.4961073 ],\n",
              "       [0.49612948],\n",
              "       [0.49616912],\n",
              "       [0.4954837 ],\n",
              "       [0.4962128 ],\n",
              "       [0.49611118],\n",
              "       [0.4961866 ],\n",
              "       [0.49588388],\n",
              "       [0.49619395],\n",
              "       [0.49603042],\n",
              "       [0.49611032],\n",
              "       [0.49615306],\n",
              "       [0.4961295 ],\n",
              "       [0.49617103],\n",
              "       [0.49602142],\n",
              "       [0.4959659 ],\n",
              "       [0.49609193],\n",
              "       [0.49611506],\n",
              "       [0.49610505],\n",
              "       [0.4961717 ],\n",
              "       [0.4961366 ],\n",
              "       [0.49599668],\n",
              "       [0.49602768],\n",
              "       [0.49607497],\n",
              "       [0.49593627],\n",
              "       [0.49611983],\n",
              "       [0.49603808],\n",
              "       [0.49614096],\n",
              "       [0.49603584],\n",
              "       [0.49615586],\n",
              "       [0.49606177],\n",
              "       [0.49612606],\n",
              "       [0.49609655],\n",
              "       [0.49619845],\n",
              "       [0.49617147],\n",
              "       [0.49613217],\n",
              "       [0.49612936],\n",
              "       [0.49613675],\n",
              "       [0.49611032],\n",
              "       [0.49607038],\n",
              "       [0.49617037],\n",
              "       [0.49604976],\n",
              "       [0.4962152 ],\n",
              "       [0.49609232],\n",
              "       [0.495885  ],\n",
              "       [0.49599868],\n",
              "       [0.4962005 ],\n",
              "       [0.4961578 ],\n",
              "       [0.49612105],\n",
              "       [0.49589536],\n",
              "       [0.49605966],\n",
              "       [0.4960917 ],\n",
              "       [0.49621314],\n",
              "       [0.49612924],\n",
              "       [0.49618647],\n",
              "       [0.49607193],\n",
              "       [0.49620205],\n",
              "       [0.49616972],\n",
              "       [0.49603721],\n",
              "       [0.49606204],\n",
              "       [0.49620393],\n",
              "       [0.49614838],\n",
              "       [0.4961968 ],\n",
              "       [0.4961233 ],\n",
              "       [0.49620095],\n",
              "       [0.49607196],\n",
              "       [0.4959411 ],\n",
              "       [0.49617472],\n",
              "       [0.49613327],\n",
              "       [0.4960925 ],\n",
              "       [0.49598068],\n",
              "       [0.4960871 ],\n",
              "       [0.49612185],\n",
              "       [0.49615726],\n",
              "       [0.49611542],\n",
              "       [0.49616662],\n",
              "       [0.49615702],\n",
              "       [0.49607816],\n",
              "       [0.49613374],\n",
              "       [0.4961519 ],\n",
              "       [0.49621356],\n",
              "       [0.49609149],\n",
              "       [0.49605328],\n",
              "       [0.49607325],\n",
              "       [0.49595323],\n",
              "       [0.4961401 ],\n",
              "       [0.4960816 ],\n",
              "       [0.4960007 ],\n",
              "       [0.4959944 ],\n",
              "       [0.49618793],\n",
              "       [0.4960427 ],\n",
              "       [0.49605346],\n",
              "       [0.4961319 ],\n",
              "       [0.4960782 ],\n",
              "       [0.49614167],\n",
              "       [0.49593133],\n",
              "       [0.4961997 ],\n",
              "       [0.4961478 ],\n",
              "       [0.4960679 ],\n",
              "       [0.4961174 ],\n",
              "       [0.49607843],\n",
              "       [0.49610034],\n",
              "       [0.49580792],\n",
              "       [0.49615556],\n",
              "       [0.49612966],\n",
              "       [0.4961579 ],\n",
              "       [0.4960074 ],\n",
              "       [0.49614155],\n",
              "       [0.49617353],\n",
              "       [0.49614298],\n",
              "       [0.4962245 ],\n",
              "       [0.49613512],\n",
              "       [0.4960201 ],\n",
              "       [0.49612173],\n",
              "       [0.49609986],\n",
              "       [0.49605215],\n",
              "       [0.49614227],\n",
              "       [0.4959452 ],\n",
              "       [0.49605787],\n",
              "       [0.4959805 ],\n",
              "       [0.49612987],\n",
              "       [0.49594977],\n",
              "       [0.49609894],\n",
              "       [0.4961373 ],\n",
              "       [0.4960538 ],\n",
              "       [0.49601644],\n",
              "       [0.49605235],\n",
              "       [0.4961638 ],\n",
              "       [0.49610618],\n",
              "       [0.49607745],\n",
              "       [0.49605033],\n",
              "       [0.49614787],\n",
              "       [0.49618253],\n",
              "       [0.4961047 ],\n",
              "       [0.49608186],\n",
              "       [0.4959678 ],\n",
              "       [0.49592814],\n",
              "       [0.49600598],\n",
              "       [0.49575475],\n",
              "       [0.4960992 ],\n",
              "       [0.49611315],\n",
              "       [0.49605048],\n",
              "       [0.49611023],\n",
              "       [0.49613965],\n",
              "       [0.49603468],\n",
              "       [0.49595496],\n",
              "       [0.49620536],\n",
              "       [0.49611908],\n",
              "       [0.4961523 ],\n",
              "       [0.49616045],\n",
              "       [0.4953735 ],\n",
              "       [0.49604785],\n",
              "       [0.49593475],\n",
              "       [0.49561876],\n",
              "       [0.49600056],\n",
              "       [0.49611136],\n",
              "       [0.49613348],\n",
              "       [0.49603269],\n",
              "       [0.4960179 ],\n",
              "       [0.49617776],\n",
              "       [0.49601564],\n",
              "       [0.49611202],\n",
              "       [0.49613214],\n",
              "       [0.49591294],\n",
              "       [0.4961391 ],\n",
              "       [0.49601814],\n",
              "       [0.49610838],\n",
              "       [0.49604326],\n",
              "       [0.49586132],\n",
              "       [0.49600542],\n",
              "       [0.4960607 ],\n",
              "       [0.49619702],\n",
              "       [0.49612328],\n",
              "       [0.49603695],\n",
              "       [0.49611846],\n",
              "       [0.49609175],\n",
              "       [0.4961244 ],\n",
              "       [0.49618596],\n",
              "       [0.49601224],\n",
              "       [0.49606118],\n",
              "       [0.49610612],\n",
              "       [0.49617326],\n",
              "       [0.49610218],\n",
              "       [0.49611768],\n",
              "       [0.496123  ],\n",
              "       [0.49568012],\n",
              "       [0.49597588],\n",
              "       [0.49606898],\n",
              "       [0.49555525],\n",
              "       [0.49608776],\n",
              "       [0.49554807],\n",
              "       [0.49616155],\n",
              "       [0.49607715],\n",
              "       [0.4959071 ],\n",
              "       [0.4960875 ],\n",
              "       [0.49605376],\n",
              "       [0.49586394],\n",
              "       [0.49610746],\n",
              "       [0.49610278],\n",
              "       [0.4960941 ],\n",
              "       [0.49605647],\n",
              "       [0.49604037],\n",
              "       [0.49582613],\n",
              "       [0.49591625],\n",
              "       [0.49607491],\n",
              "       [0.49610758],\n",
              "       [0.49614513],\n",
              "       [0.49600023],\n",
              "       [0.4961578 ],\n",
              "       [0.49609238],\n",
              "       [0.49620032],\n",
              "       [0.4962181 ],\n",
              "       [0.49608043],\n",
              "       [0.49607235],\n",
              "       [0.49611893],\n",
              "       [0.49601993],\n",
              "       [0.4960699 ],\n",
              "       [0.49608776],\n",
              "       [0.49607775],\n",
              "       [0.49610606],\n",
              "       [0.49621603],\n",
              "       [0.4958363 ],\n",
              "       [0.49610925],\n",
              "       [0.4961497 ],\n",
              "       [0.49615815],\n",
              "       [0.4959606 ],\n",
              "       [0.49603176],\n",
              "       [0.49615124],\n",
              "       [0.49608725],\n",
              "       [0.49617594],\n",
              "       [0.4960998 ],\n",
              "       [0.4960858 ],\n",
              "       [0.4960732 ],\n",
              "       [0.49602526],\n",
              "       [0.496165  ],\n",
              "       [0.49612507],\n",
              "       [0.4960772 ],\n",
              "       [0.49617684],\n",
              "       [0.49616638],\n",
              "       [0.4960951 ],\n",
              "       [0.4962124 ],\n",
              "       [0.4960522 ],\n",
              "       [0.4960644 ],\n",
              "       [0.49599797],\n",
              "       [0.49618536],\n",
              "       [0.49610445],\n",
              "       [0.49615893],\n",
              "       [0.49614474],\n",
              "       [0.4960469 ],\n",
              "       [0.4960765 ],\n",
              "       [0.49613485],\n",
              "       [0.496173  ],\n",
              "       [0.4961249 ],\n",
              "       [0.49614552],\n",
              "       [0.49609444],\n",
              "       [0.4961939 ],\n",
              "       [0.49612936],\n",
              "       [0.49610835],\n",
              "       [0.49603838],\n",
              "       [0.49605447],\n",
              "       [0.4961439 ],\n",
              "       [0.49612102],\n",
              "       [0.49606764],\n",
              "       [0.4960703 ],\n",
              "       [0.49609858],\n",
              "       [0.49591988],\n",
              "       [0.49601692],\n",
              "       [0.4961171 ],\n",
              "       [0.49593046],\n",
              "       [0.49617642],\n",
              "       [0.49609956],\n",
              "       [0.4961587 ],\n",
              "       [0.4960313 ],\n",
              "       [0.49605078],\n",
              "       [0.4961431 ],\n",
              "       [0.4962153 ],\n",
              "       [0.4961479 ],\n",
              "       [0.4962056 ],\n",
              "       [0.49601936],\n",
              "       [0.49602264],\n",
              "       [0.4960999 ],\n",
              "       [0.49616778],\n",
              "       [0.49604857],\n",
              "       [0.49611485],\n",
              "       [0.49559683],\n",
              "       [0.49555767],\n",
              "       [0.49601457],\n",
              "       [0.4960861 ],\n",
              "       [0.4960696 ],\n",
              "       [0.49608514],\n",
              "       [0.49614096],\n",
              "       [0.49539044],\n",
              "       [0.4960832 ],\n",
              "       [0.49606368],\n",
              "       [0.49610084],\n",
              "       [0.4957505 ],\n",
              "       [0.4961002 ],\n",
              "       [0.49620008],\n",
              "       [0.49601424],\n",
              "       [0.4961131 ],\n",
              "       [0.49610916],\n",
              "       [0.49608785],\n",
              "       [0.496167  ],\n",
              "       [0.49606535],\n",
              "       [0.4961481 ],\n",
              "       [0.4959937 ],\n",
              "       [0.49604166],\n",
              "       [0.49598154],\n",
              "       [0.49601904],\n",
              "       [0.4961132 ],\n",
              "       [0.49617186],\n",
              "       [0.49617943],\n",
              "       [0.49604246],\n",
              "       [0.49612448],\n",
              "       [0.49598163],\n",
              "       [0.4961487 ],\n",
              "       [0.49609426],\n",
              "       [0.4961866 ],\n",
              "       [0.49581906],\n",
              "       [0.49614435],\n",
              "       [0.4960899 ],\n",
              "       [0.49607876],\n",
              "       [0.4961701 ],\n",
              "       [0.4960366 ],\n",
              "       [0.49606803],\n",
              "       [0.49595374],\n",
              "       [0.49615276],\n",
              "       [0.49598637],\n",
              "       [0.49615988],\n",
              "       [0.49604294],\n",
              "       [0.4960633 ],\n",
              "       [0.49603528],\n",
              "       [0.49613693],\n",
              "       [0.49604937],\n",
              "       [0.49608076],\n",
              "       [0.49567783],\n",
              "       [0.49615684],\n",
              "       [0.49598408],\n",
              "       [0.49584946],\n",
              "       [0.49618167],\n",
              "       [0.49614686],\n",
              "       [0.49606287],\n",
              "       [0.4961253 ],\n",
              "       [0.49610525],\n",
              "       [0.49585328],\n",
              "       [0.49605697],\n",
              "       [0.49575892],\n",
              "       [0.49620566],\n",
              "       [0.4960817 ],\n",
              "       [0.49599013],\n",
              "       [0.49610144],\n",
              "       [0.4961706 ],\n",
              "       [0.4960013 ],\n",
              "       [0.49610543],\n",
              "       [0.49611872],\n",
              "       [0.49614307],\n",
              "       [0.4959974 ],\n",
              "       [0.4958662 ],\n",
              "       [0.4961444 ],\n",
              "       [0.4961256 ],\n",
              "       [0.49566868],\n",
              "       [0.49544677],\n",
              "       [0.4961034 ],\n",
              "       [0.49614424],\n",
              "       [0.49593133],\n",
              "       [0.49601233],\n",
              "       [0.49614543],\n",
              "       [0.49621677],\n",
              "       [0.49614578],\n",
              "       [0.49605182],\n",
              "       [0.49614835],\n",
              "       [0.49615827],\n",
              "       [0.4959132 ],\n",
              "       [0.49602103],\n",
              "       [0.49608448],\n",
              "       [0.49615836],\n",
              "       [0.49605325],\n",
              "       [0.49617404],\n",
              "       [0.49620852],\n",
              "       [0.4960961 ],\n",
              "       [0.49613   ],\n",
              "       [0.4961728 ],\n",
              "       [0.4961211 ],\n",
              "       [0.49613175],\n",
              "       [0.4961604 ],\n",
              "       [0.49614066],\n",
              "       [0.49614623],\n",
              "       [0.49599704],\n",
              "       [0.4960455 ],\n",
              "       [0.49610466],\n",
              "       [0.49611637],\n",
              "       [0.49611294],\n",
              "       [0.49599376],\n",
              "       [0.49608365],\n",
              "       [0.49612302],\n",
              "       [0.49617016],\n",
              "       [0.49621913],\n",
              "       [0.4961458 ],\n",
              "       [0.4958637 ],\n",
              "       [0.49617648],\n",
              "       [0.49602646],\n",
              "       [0.4960068 ],\n",
              "       [0.49604943],\n",
              "       [0.49603304],\n",
              "       [0.49586454],\n",
              "       [0.4961478 ],\n",
              "       [0.49620146],\n",
              "       [0.49608818],\n",
              "       [0.49612   ],\n",
              "       [0.49614617],\n",
              "       [0.49591237],\n",
              "       [0.49592835],\n",
              "       [0.49604687],\n",
              "       [0.49616504],\n",
              "       [0.49610585],\n",
              "       [0.49604955],\n",
              "       [0.4960211 ],\n",
              "       [0.49615252],\n",
              "       [0.49608982],\n",
              "       [0.49611995],\n",
              "       [0.49609688],\n",
              "       [0.4959893 ],\n",
              "       [0.49595603],\n",
              "       [0.4960066 ],\n",
              "       [0.49615288],\n",
              "       [0.496037  ],\n",
              "       [0.4961243 ],\n",
              "       [0.49612868],\n",
              "       [0.49616975],\n",
              "       [0.49616152],\n",
              "       [0.49607173],\n",
              "       [0.49611184],\n",
              "       [0.4961288 ],\n",
              "       [0.49615106],\n",
              "       [0.49602392],\n",
              "       [0.49598178],\n",
              "       [0.49615547],\n",
              "       [0.495611  ],\n",
              "       [0.49615666],\n",
              "       [0.49619475],\n",
              "       [0.4960644 ],\n",
              "       [0.4961291 ],\n",
              "       [0.4961265 ],\n",
              "       [0.49606562],\n",
              "       [0.49614528],\n",
              "       [0.49614   ],\n",
              "       [0.49603504],\n",
              "       [0.49618667],\n",
              "       [0.49615696],\n",
              "       [0.49613777],\n",
              "       [0.495945  ],\n",
              "       [0.49614504],\n",
              "       [0.49600378],\n",
              "       [0.4960431 ],\n",
              "       [0.49608502],\n",
              "       [0.49616754],\n",
              "       [0.495918  ],\n",
              "       [0.49590042],\n",
              "       [0.4961843 ],\n",
              "       [0.49615157],\n",
              "       [0.4958742 ],\n",
              "       [0.49615395],\n",
              "       [0.4961697 ],\n",
              "       [0.4960723 ],\n",
              "       [0.49612865],\n",
              "       [0.49614576],\n",
              "       [0.49613363],\n",
              "       [0.49595034],\n",
              "       [0.4960633 ],\n",
              "       [0.49612844],\n",
              "       [0.49614042],\n",
              "       [0.49607113],\n",
              "       [0.4960025 ],\n",
              "       [0.49603337],\n",
              "       [0.49514765],\n",
              "       [0.49604663]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0IYWxDHSZ4v",
        "colab_type": "code",
        "outputId": "7cd82795-ec46-47b3-a8f4-72cf96347482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "lstm_attention.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fd7ee965a58>,\n",
              " <tensorflow.python.keras.layers.embeddings.Embedding at 0x7fd7ee965f28>,\n",
              " <tensorflow.python.keras.layers.recurrent.LSTM at 0x7fd7ee965828>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fd7ee918cc0>,\n",
              " <tensorflow.python.keras.layers.core.Flatten at 0x7fd7ee93cf28>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fd7ee8a8e10>,\n",
              " <tensorflow.python.keras.layers.core.RepeatVector at 0x7fd7ee918860>,\n",
              " <tensorflow.python.keras.layers.core.Permute at 0x7fd7ee84a7b8>,\n",
              " <tensorflow.python.keras.layers.merge.Multiply at 0x7fd7ee84ad68>,\n",
              " <tensorflow.python.keras.layers.core.Lambda at 0x7fd7ee8507f0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fd7ee850748>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLjq0aalSmrq",
        "colab_type": "code",
        "outputId": "87e5072b-3343-4969-cc60-08160016fe13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "for layer in lstm_attention.layers:\n",
        "    print(layer.output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input_16:0\", shape=(?, 1695), dtype=float32)\n",
            "Tensor(\"embedding_24/embedding_lookup/Identity_1:0\", shape=(?, 1695, 64), dtype=float32)\n",
            "Tensor(\"lstm_24/transpose_1:0\", shape=(?, 1695, 10), dtype=float32)\n",
            "Tensor(\"dense_25/Tanh:0\", shape=(?, 1695, 1), dtype=float32)\n",
            "Tensor(\"flatten_24/Reshape:0\", shape=(?, 1695), dtype=float32)\n",
            "Tensor(\"activation_12/Softmax:0\", shape=(?, 1695), dtype=float32)\n",
            "Tensor(\"repeat_vector_12/Tile:0\", shape=(?, 10, 1695), dtype=float32)\n",
            "Tensor(\"permute_12/transpose:0\", shape=(?, 1695, 10), dtype=float32)\n",
            "Tensor(\"multiply_12/mul:0\", shape=(?, 1695, 10), dtype=float32)\n",
            "Tensor(\"lambda_12/Sum:0\", shape=(?, 10), dtype=float32)\n",
            "Tensor(\"dense_26/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQOZ1gFvtz9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create Bidirectional LSTM with Attention using Keras Functional API\n",
        "def create_bi_lstm_with_attention():\n",
        "    _input = Input(shape=[MAX_LENGTH])\n",
        "    embedded = Embedding(\n",
        "            input_dim=NUM_CHARS,\n",
        "            output_dim=EMBEDDING_SIZE,\n",
        "            input_length=MAX_LENGTH,\n",
        "            trainable=False,\n",
        "            mask_zero=False\n",
        "        )(_input)\n",
        "    activations = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True))(embedded)\n",
        "    # Attention\n",
        "    attention = Dense(1, activation='tanh')(activations)\n",
        "    attention = Flatten()(attention)\n",
        "    attention = Activation('softmax')(attention)\n",
        "    attention = RepeatVector(2*HIDDEN_SIZE)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "    output_attention = multiply([activations, attention])\n",
        "\n",
        "    # output_attention = LSTM(HIDDEN_SIZE)(output_attention)\n",
        "    output_attention = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(HIDDEN_SIZE,))(output_attention)\n",
        "    output = Dense(1, activation='sigmoid')(output_attention)\n",
        "    bi_lstm_attention = Model(inputs=[_input], outputs=output, name=\"bi_lstm_attention\")\n",
        "    return bi_lstm_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp1clmCI-Wac",
        "colab_type": "code",
        "outputId": "7d5cb7c6-b8f3-4987-d48a-9f8bcff9ece8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "bi_lstm_attention = create_bi_lstm_with_attention()\n",
        "bi_lstm_attention.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(bi_lstm_attention.summary())\n",
        "\n",
        "bi_lstm_attention.fit(X_train_main, y_train_main,\n",
        "                         validation_data=(X_train_val, y_train_val),\n",
        "                         epochs=1, batch_size=1024, class_weight=class_weights_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"bi_lstm_attention\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 1695)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_27 (Embedding)        (None, 1695, 64)     8192        input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 1695, 20)     6000        embedding_27[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 1695, 1)      21          bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_28 (Flatten)            (None, 1695)         0           dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 1695)         0           flatten_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_15 (RepeatVector) (None, 20, 1695)     0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "permute_15 (Permute)            (None, 1695, 20)     0           repeat_vector_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "multiply_15 (Multiply)          (None, 1695, 20)     0           bidirectional_2[0][0]            \n",
            "                                                                 permute_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 20)           0           multiply_15[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 1)            21          lambda_13[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,234\n",
            "Trainable params: 6,042\n",
            "Non-trainable params: 8,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 1683 samples, validate on 421 samples\n",
            "1683/1683 [==============================] - 12s 7ms/sample - loss: 0.6847 - acc: 0.9186 - val_loss: 0.6817 - val_acc: 0.9074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faf9f19fc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFpIZ1p27lrt",
        "colab_type": "code",
        "outputId": "4f42c159-c118-4118-bb92-60eb0a7ce4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "for layer in bi_lstm_attention.layers:\n",
        "    print(layer.output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input_19:0\", shape=(?, 1695), dtype=float32)\n",
            "Tensor(\"embedding_27/embedding_lookup/Identity_1:0\", shape=(?, 1695, 64), dtype=float32)\n",
            "Tensor(\"bidirectional_2/concat:0\", shape=(?, 1695, 20), dtype=float32)\n",
            "Tensor(\"dense_30/Tanh:0\", shape=(?, 1695, 1), dtype=float32)\n",
            "Tensor(\"flatten_28/Reshape:0\", shape=(?, 1695), dtype=float32)\n",
            "Tensor(\"activation_15/Softmax:0\", shape=(?, 1695), dtype=float32)\n",
            "Tensor(\"repeat_vector_15/Tile:0\", shape=(?, 20, 1695), dtype=float32)\n",
            "Tensor(\"permute_15/transpose:0\", shape=(?, 1695, 20), dtype=float32)\n",
            "Tensor(\"multiply_15/mul:0\", shape=(?, 1695, 20), dtype=float32)\n",
            "Tensor(\"lambda_13/Sum:0\", shape=(?, 20), dtype=float32)\n",
            "Tensor(\"dense_31/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbNYZ3mk-bpB",
        "colab_type": "code",
        "outputId": "df6d07af-2008-4fe4-e946-1cd02ba63f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predictions_bi_lstm_attention, rounded_bi_lstm_attention = evaluate_precision_recall(bi_lstm_attention, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.920303605313093\n",
            "Recall: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6v5LOAh8HRD",
        "colab_type": "code",
        "outputId": "e6d5a277-d507-4a79-dc5c-a07318f61140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions_bi_lstm_attention"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49279505],\n",
              "       [0.49278334],\n",
              "       [0.49282378],\n",
              "       [0.49290022],\n",
              "       [0.49274424],\n",
              "       [0.49280027],\n",
              "       [0.49284464],\n",
              "       [0.49289772],\n",
              "       [0.49282852],\n",
              "       [0.49298853],\n",
              "       [0.49282432],\n",
              "       [0.4929398 ],\n",
              "       [0.49289438],\n",
              "       [0.49284768],\n",
              "       [0.4928056 ],\n",
              "       [0.49273527],\n",
              "       [0.4928078 ],\n",
              "       [0.49285936],\n",
              "       [0.49352923],\n",
              "       [0.49284142],\n",
              "       [0.4928773 ],\n",
              "       [0.49280974],\n",
              "       [0.49281394],\n",
              "       [0.49290928],\n",
              "       [0.4928471 ],\n",
              "       [0.4927938 ],\n",
              "       [0.49299645],\n",
              "       [0.49297532],\n",
              "       [0.49281278],\n",
              "       [0.4928103 ],\n",
              "       [0.49279988],\n",
              "       [0.49309644],\n",
              "       [0.49296218],\n",
              "       [0.49295136],\n",
              "       [0.4928891 ],\n",
              "       [0.49289304],\n",
              "       [0.4927944 ],\n",
              "       [0.49284866],\n",
              "       [0.49278468],\n",
              "       [0.4928492 ],\n",
              "       [0.49282867],\n",
              "       [0.4928429 ],\n",
              "       [0.49317837],\n",
              "       [0.49278235],\n",
              "       [0.4929482 ],\n",
              "       [0.49283925],\n",
              "       [0.4927866 ],\n",
              "       [0.49281675],\n",
              "       [0.4931284 ],\n",
              "       [0.49293962],\n",
              "       [0.49313477],\n",
              "       [0.49281687],\n",
              "       [0.49280658],\n",
              "       [0.49279994],\n",
              "       [0.49326724],\n",
              "       [0.49280038],\n",
              "       [0.4929061 ],\n",
              "       [0.4928839 ],\n",
              "       [0.49301228],\n",
              "       [0.49281955],\n",
              "       [0.49290466],\n",
              "       [0.4928171 ],\n",
              "       [0.49288636],\n",
              "       [0.49277282],\n",
              "       [0.4927874 ],\n",
              "       [0.4928192 ],\n",
              "       [0.49301073],\n",
              "       [0.49285075],\n",
              "       [0.49286795],\n",
              "       [0.49283007],\n",
              "       [0.49281028],\n",
              "       [0.49285182],\n",
              "       [0.4929778 ],\n",
              "       [0.49296543],\n",
              "       [0.49280322],\n",
              "       [0.49294522],\n",
              "       [0.4928497 ],\n",
              "       [0.4929689 ],\n",
              "       [0.4928469 ],\n",
              "       [0.49285722],\n",
              "       [0.49282432],\n",
              "       [0.4928398 ],\n",
              "       [0.49280164],\n",
              "       [0.49279293],\n",
              "       [0.49281064],\n",
              "       [0.49281633],\n",
              "       [0.4928237 ],\n",
              "       [0.49291754],\n",
              "       [0.4928375 ],\n",
              "       [0.49292257],\n",
              "       [0.49295202],\n",
              "       [0.4928154 ],\n",
              "       [0.4929197 ],\n",
              "       [0.4927884 ],\n",
              "       [0.4928376 ],\n",
              "       [0.4929834 ],\n",
              "       [0.4929631 ],\n",
              "       [0.4928303 ],\n",
              "       [0.4928198 ],\n",
              "       [0.49282423],\n",
              "       [0.49295586],\n",
              "       [0.49288374],\n",
              "       [0.49279946],\n",
              "       [0.492808  ],\n",
              "       [0.4927904 ],\n",
              "       [0.4928162 ],\n",
              "       [0.49282998],\n",
              "       [0.49277833],\n",
              "       [0.49273598],\n",
              "       [0.49290815],\n",
              "       [0.4928766 ],\n",
              "       [0.49283323],\n",
              "       [0.49283266],\n",
              "       [0.4928056 ],\n",
              "       [0.4928623 ],\n",
              "       [0.49285668],\n",
              "       [0.49285072],\n",
              "       [0.4930101 ],\n",
              "       [0.4928513 ],\n",
              "       [0.4927707 ],\n",
              "       [0.49285114],\n",
              "       [0.49300918],\n",
              "       [0.49285772],\n",
              "       [0.49286094],\n",
              "       [0.49288806],\n",
              "       [0.49287325],\n",
              "       [0.4928072 ],\n",
              "       [0.4928611 ],\n",
              "       [0.49282196],\n",
              "       [0.49291086],\n",
              "       [0.4928911 ],\n",
              "       [0.49282962],\n",
              "       [0.49287167],\n",
              "       [0.4929827 ],\n",
              "       [0.49283785],\n",
              "       [0.49296495],\n",
              "       [0.49279508],\n",
              "       [0.49287355],\n",
              "       [0.49298352],\n",
              "       [0.49291933],\n",
              "       [0.49289474],\n",
              "       [0.4928863 ],\n",
              "       [0.4928736 ],\n",
              "       [0.49280235],\n",
              "       [0.49281108],\n",
              "       [0.49281904],\n",
              "       [0.49283582],\n",
              "       [0.49282953],\n",
              "       [0.4928184 ],\n",
              "       [0.49285954],\n",
              "       [0.4927393 ],\n",
              "       [0.49293298],\n",
              "       [0.49284762],\n",
              "       [0.4930486 ],\n",
              "       [0.49282867],\n",
              "       [0.49275804],\n",
              "       [0.49277705],\n",
              "       [0.49289012],\n",
              "       [0.49280903],\n",
              "       [0.4928172 ],\n",
              "       [0.49279258],\n",
              "       [0.49287018],\n",
              "       [0.4928567 ],\n",
              "       [0.4930278 ],\n",
              "       [0.49285844],\n",
              "       [0.49284002],\n",
              "       [0.4929192 ],\n",
              "       [0.49278447],\n",
              "       [0.4929124 ],\n",
              "       [0.49287707],\n",
              "       [0.49301118],\n",
              "       [0.49286848],\n",
              "       [0.49296868],\n",
              "       [0.49289086],\n",
              "       [0.49279872],\n",
              "       [0.4929083 ],\n",
              "       [0.49287745],\n",
              "       [0.49294877],\n",
              "       [0.49280018],\n",
              "       [0.49286577],\n",
              "       [0.4928836 ],\n",
              "       [0.49291274],\n",
              "       [0.4928261 ],\n",
              "       [0.49278647],\n",
              "       [0.4927713 ],\n",
              "       [0.49285686],\n",
              "       [0.49297532],\n",
              "       [0.49302086],\n",
              "       [0.4929124 ],\n",
              "       [0.4929829 ],\n",
              "       [0.4928729 ],\n",
              "       [0.49287683],\n",
              "       [0.49291047],\n",
              "       [0.4928295 ],\n",
              "       [0.4928113 ],\n",
              "       [0.49277195],\n",
              "       [0.4929566 ],\n",
              "       [0.49280804],\n",
              "       [0.49287203],\n",
              "       [0.4928364 ],\n",
              "       [0.49280694],\n",
              "       [0.49309802],\n",
              "       [0.492889  ],\n",
              "       [0.49300832],\n",
              "       [0.49313098],\n",
              "       [0.49299192],\n",
              "       [0.49288777],\n",
              "       [0.4928191 ],\n",
              "       [0.4929614 ],\n",
              "       [0.49294594],\n",
              "       [0.49285147],\n",
              "       [0.49299654],\n",
              "       [0.49280083],\n",
              "       [0.4927949 ],\n",
              "       [0.49300474],\n",
              "       [0.49278995],\n",
              "       [0.49290878],\n",
              "       [0.49287644],\n",
              "       [0.49283093],\n",
              "       [0.49301022],\n",
              "       [0.49289724],\n",
              "       [0.49284244],\n",
              "       [0.49280405],\n",
              "       [0.49283817],\n",
              "       [0.4929718 ],\n",
              "       [0.49281928],\n",
              "       [0.49287993],\n",
              "       [0.4928078 ],\n",
              "       [0.49281073],\n",
              "       [0.49297124],\n",
              "       [0.49287948],\n",
              "       [0.49282807],\n",
              "       [0.4928018 ],\n",
              "       [0.49278012],\n",
              "       [0.4928253 ],\n",
              "       [0.49284765],\n",
              "       [0.49311697],\n",
              "       [0.49297887],\n",
              "       [0.49282393],\n",
              "       [0.49332714],\n",
              "       [0.49281293],\n",
              "       [0.49317548],\n",
              "       [0.49280474],\n",
              "       [0.49297163],\n",
              "       [0.49295786],\n",
              "       [0.492886  ],\n",
              "       [0.49290037],\n",
              "       [0.4928609 ],\n",
              "       [0.49295664],\n",
              "       [0.49279076],\n",
              "       [0.4928484 ],\n",
              "       [0.4929145 ],\n",
              "       [0.4929569 ],\n",
              "       [0.49313086],\n",
              "       [0.49300957],\n",
              "       [0.49292845],\n",
              "       [0.49287978],\n",
              "       [0.49278384],\n",
              "       [0.49295634],\n",
              "       [0.49280393],\n",
              "       [0.49288365],\n",
              "       [0.49285248],\n",
              "       [0.49280262],\n",
              "       [0.49284637],\n",
              "       [0.4927918 ],\n",
              "       [0.49281663],\n",
              "       [0.49281543],\n",
              "       [0.4928956 ],\n",
              "       [0.49285725],\n",
              "       [0.4928594 ],\n",
              "       [0.49292952],\n",
              "       [0.49283963],\n",
              "       [0.493017  ],\n",
              "       [0.49286875],\n",
              "       [0.49280986],\n",
              "       [0.49279448],\n",
              "       [0.49297926],\n",
              "       [0.49299344],\n",
              "       [0.49278942],\n",
              "       [0.4928251 ],\n",
              "       [0.4928455 ],\n",
              "       [0.4928611 ],\n",
              "       [0.4928017 ],\n",
              "       [0.49283472],\n",
              "       [0.4929812 ],\n",
              "       [0.4928216 ],\n",
              "       [0.4927634 ],\n",
              "       [0.49284896],\n",
              "       [0.4928562 ],\n",
              "       [0.49286968],\n",
              "       [0.49291986],\n",
              "       [0.492813  ],\n",
              "       [0.49295595],\n",
              "       [0.4928459 ],\n",
              "       [0.49289644],\n",
              "       [0.49279508],\n",
              "       [0.4929322 ],\n",
              "       [0.49278998],\n",
              "       [0.49280342],\n",
              "       [0.4928881 ],\n",
              "       [0.49280357],\n",
              "       [0.49284545],\n",
              "       [0.4927986 ],\n",
              "       [0.49287504],\n",
              "       [0.49279344],\n",
              "       [0.4927499 ],\n",
              "       [0.4928492 ],\n",
              "       [0.4928191 ],\n",
              "       [0.4928521 ],\n",
              "       [0.49285686],\n",
              "       [0.4929488 ],\n",
              "       [0.49286482],\n",
              "       [0.49284744],\n",
              "       [0.49286208],\n",
              "       [0.49280313],\n",
              "       [0.4928463 ],\n",
              "       [0.49293458],\n",
              "       [0.49297392],\n",
              "       [0.4928374 ],\n",
              "       [0.49293151],\n",
              "       [0.49278712],\n",
              "       [0.49279892],\n",
              "       [0.49283424],\n",
              "       [0.49295914],\n",
              "       [0.49278918],\n",
              "       [0.49285448],\n",
              "       [0.49277368],\n",
              "       [0.49278393],\n",
              "       [0.49281567],\n",
              "       [0.4928798 ],\n",
              "       [0.49300513],\n",
              "       [0.49284816],\n",
              "       [0.49284273],\n",
              "       [0.492949  ],\n",
              "       [0.4928896 ],\n",
              "       [0.4932749 ],\n",
              "       [0.49307063],\n",
              "       [0.4926902 ],\n",
              "       [0.4928054 ],\n",
              "       [0.49291465],\n",
              "       [0.49286816],\n",
              "       [0.49285313],\n",
              "       [0.49320874],\n",
              "       [0.49286422],\n",
              "       [0.49294135],\n",
              "       [0.4928185 ],\n",
              "       [0.4930323 ],\n",
              "       [0.49289185],\n",
              "       [0.4928425 ],\n",
              "       [0.49292508],\n",
              "       [0.49293318],\n",
              "       [0.4928133 ],\n",
              "       [0.49296376],\n",
              "       [0.49280038],\n",
              "       [0.49288562],\n",
              "       [0.4928182 ],\n",
              "       [0.49296707],\n",
              "       [0.49292234],\n",
              "       [0.49305207],\n",
              "       [0.49285665],\n",
              "       [0.49281982],\n",
              "       [0.49283522],\n",
              "       [0.4928    ],\n",
              "       [0.49290308],\n",
              "       [0.49286026],\n",
              "       [0.4929976 ],\n",
              "       [0.49282396],\n",
              "       [0.49285093],\n",
              "       [0.49284017],\n",
              "       [0.4930166 ],\n",
              "       [0.49290583],\n",
              "       [0.49281898],\n",
              "       [0.49282455],\n",
              "       [0.49279612],\n",
              "       [0.4928895 ],\n",
              "       [0.49279153],\n",
              "       [0.49296832],\n",
              "       [0.49277705],\n",
              "       [0.49297214],\n",
              "       [0.49281952],\n",
              "       [0.49297145],\n",
              "       [0.4929307 ],\n",
              "       [0.49295875],\n",
              "       [0.49285638],\n",
              "       [0.4928245 ],\n",
              "       [0.49292314],\n",
              "       [0.49309662],\n",
              "       [0.49277553],\n",
              "       [0.49304283],\n",
              "       [0.49310714],\n",
              "       [0.49284673],\n",
              "       [0.49286604],\n",
              "       [0.49293473],\n",
              "       [0.49275607],\n",
              "       [0.49281654],\n",
              "       [0.4930508 ],\n",
              "       [0.4928918 ],\n",
              "       [0.49294353],\n",
              "       [0.4928342 ],\n",
              "       [0.4928253 ],\n",
              "       [0.4929265 ],\n",
              "       [0.49277744],\n",
              "       [0.4928283 ],\n",
              "       [0.49293867],\n",
              "       [0.4928651 ],\n",
              "       [0.49282393],\n",
              "       [0.49283746],\n",
              "       [0.4928021 ],\n",
              "       [0.49307126],\n",
              "       [0.49283522],\n",
              "       [0.49280143],\n",
              "       [0.4930557 ],\n",
              "       [0.49329686],\n",
              "       [0.49286026],\n",
              "       [0.49281   ],\n",
              "       [0.4930007 ],\n",
              "       [0.4929498 ],\n",
              "       [0.49284074],\n",
              "       [0.49284333],\n",
              "       [0.49283034],\n",
              "       [0.4928875 ],\n",
              "       [0.4928043 ],\n",
              "       [0.49278376],\n",
              "       [0.4930641 ],\n",
              "       [0.49298796],\n",
              "       [0.49283433],\n",
              "       [0.49285185],\n",
              "       [0.49295798],\n",
              "       [0.49281377],\n",
              "       [0.49282986],\n",
              "       [0.49290955],\n",
              "       [0.49283695],\n",
              "       [0.4928393 ],\n",
              "       [0.49286085],\n",
              "       [0.49283725],\n",
              "       [0.49279696],\n",
              "       [0.49283585],\n",
              "       [0.49279392],\n",
              "       [0.49299008],\n",
              "       [0.49295425],\n",
              "       [0.49284247],\n",
              "       [0.49281067],\n",
              "       [0.49288043],\n",
              "       [0.49289563],\n",
              "       [0.49286556],\n",
              "       [0.49279025],\n",
              "       [0.49279636],\n",
              "       [0.4927874 ],\n",
              "       [0.49279955],\n",
              "       [0.49318105],\n",
              "       [0.49283332],\n",
              "       [0.49293342],\n",
              "       [0.49297124],\n",
              "       [0.49285728],\n",
              "       [0.49296257],\n",
              "       [0.49293563],\n",
              "       [0.4927437 ],\n",
              "       [0.49280143],\n",
              "       [0.4928598 ],\n",
              "       [0.49281245],\n",
              "       [0.4927851 ],\n",
              "       [0.49291307],\n",
              "       [0.49290887],\n",
              "       [0.49292156],\n",
              "       [0.4928108 ],\n",
              "       [0.49278197],\n",
              "       [0.4929161 ],\n",
              "       [0.49296647],\n",
              "       [0.49297515],\n",
              "       [0.49285433],\n",
              "       [0.49285817],\n",
              "       [0.49280626],\n",
              "       [0.49297774],\n",
              "       [0.49281067],\n",
              "       [0.49292624],\n",
              "       [0.49284023],\n",
              "       [0.49302882],\n",
              "       [0.49279577],\n",
              "       [0.49281943],\n",
              "       [0.49279645],\n",
              "       [0.4927979 ],\n",
              "       [0.49291703],\n",
              "       [0.4928227 ],\n",
              "       [0.49284178],\n",
              "       [0.49281996],\n",
              "       [0.49298516],\n",
              "       [0.49296007],\n",
              "       [0.49288625],\n",
              "       [0.4929427 ],\n",
              "       [0.49277353],\n",
              "       [0.49284104],\n",
              "       [0.49283782],\n",
              "       [0.49281842],\n",
              "       [0.49284518],\n",
              "       [0.49287197],\n",
              "       [0.49272794],\n",
              "       [0.49280384],\n",
              "       [0.4928883 ],\n",
              "       [0.49280477],\n",
              "       [0.49283564],\n",
              "       [0.49285167],\n",
              "       [0.49292436],\n",
              "       [0.49275985],\n",
              "       [0.49303192],\n",
              "       [0.49296254],\n",
              "       [0.49279237],\n",
              "       [0.4927848 ],\n",
              "       [0.49293956],\n",
              "       [0.49306643],\n",
              "       [0.49281475],\n",
              "       [0.4927333 ],\n",
              "       [0.49306446],\n",
              "       [0.4928183 ],\n",
              "       [0.49282345],\n",
              "       [0.4928454 ],\n",
              "       [0.49287516],\n",
              "       [0.49281195],\n",
              "       [0.49283573],\n",
              "       [0.49297893],\n",
              "       [0.49296007],\n",
              "       [0.4928437 ],\n",
              "       [0.4928796 ],\n",
              "       [0.4928818 ],\n",
              "       [0.4929433 ],\n",
              "       [0.4928622 ],\n",
              "       [0.49333245],\n",
              "       [0.49293765]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FTdqroT8I3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}